{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 3: Apply SBI to Your Own Problem \ud83d\ude80\n",
        "\n",
        "**Time:** 20 minutes  \n",
        "**Goal:** Apply what you've learned to a new simulator\n",
        "\n",
        "## \ud83c\udfaf Learning Objectives\n",
        "\n",
        "By the end of this exercise, you will:\n",
        "1. \u2705 Adapt the SBI workflow to a new problem\n",
        "2. \u2705 Define appropriate priors for your parameters\n",
        "3. \u2705 Run inference and diagnostics on your simulator\n",
        "4. \u2705 Leave with working code you can adapt\n",
        "\n",
        "## Choose Your Adventure!\n",
        "\n",
        "We provide two well-tested example simulators, or you can bring your own:\n",
        "\n",
        "### \ud83c\udfbe Option A: Ball Throw Physics\n",
        "- **Story**: You're analyzing baseball pitches or golf drives\n",
        "- **Physics**: Projectile motion with air resistance\n",
        "- **Challenge**: Infer launch conditions from landing position\n",
        "\n",
        "### \ud83e\udda0 Option B: SIR Epidemic Model\n",
        "- **Story**: You're tracking disease spread in a community\n",
        "- **Model**: Classic compartmental epidemic model\n",
        "- **Challenge**: Infer transmission rates from outbreak data\n",
        "\n",
        "### \ud83d\udd2c Option C: Your Own Simulator\n",
        "- Bring your research problem!\n",
        "- We'll help you adapt it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# SBI imports\n",
        "from sbi import inference\n",
        "from sbi import analysis\n",
        "from sbi import utils\n",
        "\n",
        "# Our example simulators\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from simulators.ball_throw import ball_throw_simulator, create_ball_throw_prior\n",
        "from simulators.sir_model import sir_epidemic_simulator, create_sir_prior\n",
        ")\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"colorblind\")\n",
        "\n",
        "# Random seed\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"\u2705 Ready to apply SBI to your problem!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Explore the Simulators\n",
        "\n",
        "Let's understand what each simulator does before choosing one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83c\udfbe Ball Throw Physics\n",
        "\n",
        "This simulator models projectile motion with air resistance:\n",
        "\n",
        "**Differential equations:**\n",
        "- Horizontal: `d\u00b2x/dt\u00b2 = wind - friction\u00b7dx/dt`\n",
        "- Vertical: `d\u00b2y/dt\u00b2 = -gravity - friction\u00b7dy/dt`\n",
        "\n",
        "**Parameters to infer:**\n",
        "1. Initial velocity (5-30 m/s)\n",
        "2. Launch angle (0.2-1.4 radians \u2248 11\u00b0-80\u00b0)\n",
        "3. Friction coefficient (0.0-0.5)\n",
        "\n",
        "**What we observe:**\n",
        "- Landing distance (meters)\n",
        "- Maximum height reached (meters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the ball throw simulator\n",
        "test_params = torch.tensor([15.0, 0.8, 0.1])  # 15 m/s, ~45\u00b0, low friction\n",
        "observations = ball_throw_simulator(test_params)\n",
        "\n",
        "print(\"\ud83c\udfbe Ball Throw Test:\")\n",
        "print(f\"  Parameters: v\u2080={test_params[0]:.1f} m/s, \u03b8={test_params[1]:.2f} rad, \u03bc={test_params[2]:.2f}\")\n",
        "print(f\"  Observations: distance={observations[0]:.1f}m, max_height={observations[1]:.1f}m\")\n",
        "\n",
        "# Visualize a trajectory\n",
        "obs, x_traj, y_traj = ball_throw_simulator(test_params, return_trajectory=True)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(x_traj, y_traj, 'b-', linewidth=2, label='Trajectory')\n",
        "plt.scatter([obs[0].item()], [0], color='red', s=100, zorder=5, label='Landing')\n",
        "plt.scatter([x_traj[np.argmax(y_traj)]], [obs[1].item()], color='green', s=100, zorder=5, label='Peak')\n",
        "plt.xlabel('Distance (m)', fontsize=12)\n",
        "plt.ylabel('Height (m)', fontsize=12)\n",
        "plt.title('Ball Trajectory with Air Resistance', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\ud83d\udca1 We observe only the landing distance and max height, not the full trajectory!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83e\udda0 SIR Epidemic Model\n",
        "\n",
        "This simulator models disease spread through a population:\n",
        "\n",
        "**Compartments:**\n",
        "- **S**usceptible: Can catch the disease\n",
        "- **I**nfected: Currently sick and contagious\n",
        "- **R**ecovered: Immune after recovery\n",
        "\n",
        "**Differential equations:**\n",
        "- `dS/dt = -\u03b2\u00b7S\u00b7I/N` (infection)\n",
        "- `dI/dt = \u03b2\u00b7S\u00b7I/N - \u03b3\u00b7I` (infection - recovery)\n",
        "- `dR/dt = \u03b3\u00b7I` (recovery)\n",
        "\n",
        "**Parameters to infer:**\n",
        "1. \u03b2: Infection rate (0.1-2.0 per day)\n",
        "2. \u03b3: Recovery rate (0.05-0.5 per day)\n",
        "3. I\u2080: Initial infected count (1-100 people)\n",
        "\n",
        "**What we observe:**\n",
        "- Peak number of infected\n",
        "- Time to reach peak (days)\n",
        "- Total recovered at end\n",
        "- Epidemic duration (days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the SIR simulator\n",
        "test_params = torch.tensor([0.5, 0.1, 10])  # \u03b2=0.5, \u03b3=0.1, I\u2080=10\n",
        "observations = sir_epidemic_simulator(test_params)\n",
        "\n",
        "print(\"\ud83e\udda0 SIR Epidemic Test:\")\n",
        "print(f\"  Parameters: \u03b2={test_params[0]:.2f}, \u03b3={test_params[1]:.2f}, I\u2080={test_params[2]:.0f}\")\n",
        "print(f\"  Basic reproduction number R\u2080 = \u03b2/\u03b3 = {test_params[0]/test_params[1]:.1f}\")\n",
        "print(f\"\\n  Observations:\")\n",
        "print(f\"    Peak infected: {observations[0]:.0f} people\")\n",
        "print(f\"    Time to peak: {observations[1]:.0f} days\")\n",
        "print(f\"    Total recovered: {observations[2]:.0f} people\")\n",
        "print(f\"    Epidemic duration: {observations[3]:.0f} days\")\n",
        "\n",
        "# Visualize epidemic curves\n",
        "obs, time_series = sir_epidemic_simulator(test_params, return_time_series=True)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(time_series['t'], time_series['S'], label='Susceptible', linewidth=2, color='blue')\n",
        "plt.plot(time_series['t'], time_series['I'], label='Infected', linewidth=2, color='red')\n",
        "plt.plot(time_series['t'], time_series['R'], label='Recovered', linewidth=2, color='green')\n",
        "\n",
        "# Mark observations\n",
        "peak_idx = np.argmax(time_series['I'])\n",
        "plt.scatter([time_series['t'][peak_idx]], [time_series['I'][peak_idx]], \n",
        "           color='red', s=100, zorder=5, label=f'Peak: {obs[0]:.0f}')\n",
        "\n",
        "plt.xlabel('Time (days)', fontsize=12)\n",
        "plt.ylabel('Number of individuals', fontsize=12)\n",
        "plt.title('SIR Epidemic Dynamics (Population = 10,000)', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\ud83d\udca1 We observe summary statistics, not the full time series!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udd2c Your Own Simulator\n",
        "\n",
        "If you brought your own simulator, adapt this template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def your_simulator(params):\n",
        "    \"\"\"\n",
        "    Template for your own simulator.\n",
        "    \n",
        "    Requirements:\n",
        "    1. Takes parameters (torch.Tensor or numpy array)\n",
        "    2. Returns observations (torch.Tensor)\n",
        "    3. Should include some stochasticity (noise)\n",
        "    4. Runs reasonably fast (< 1 second)\n",
        "    \"\"\"\n",
        "    # Convert to torch if needed\n",
        "    if isinstance(params, np.ndarray):\n",
        "        params = torch.tensor(params, dtype=torch.float32)\n",
        "    \n",
        "    # Your simulation code here\n",
        "    # ...\n",
        "    \n",
        "    # Add observation noise (important!)\n",
        "    # observations = observations * (1 + torch.randn_like(observations) * 0.05)\n",
        "    \n",
        "    # Return as torch tensor\n",
        "    # return torch.tensor(observations, dtype=torch.float32)\n",
        "    \n",
        "    pass  # Remove this when implementing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Choose Your Simulator and Run SBI\n",
        "\n",
        "**\ud83d\udc47 Choose ONE option below by uncommenting the appropriate section:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== OPTION A: Ball Throw ==========\n",
        "simulator = ball_throw_simulator\n",
        "prior = create_ball_throw_prior(include_wind=False)  # Set True to include wind\n",
        "param_names = [\"v\u2080 (m/s)\", \"\u03b8 (rad)\", \"\u03bc (friction)\"]\n",
        "obs_names = [\"distance (m)\", \"max height (m)\"]\n",
        "\n",
        "# ========== OPTION B: SIR Model ==========\n",
        "# simulator = sir_epidemic_simulator\n",
        "# prior = create_sir_prior()\n",
        "# param_names = [\"\u03b2 (infection)\", \"\u03b3 (recovery)\", \"I\u2080 (initial)\"]\n",
        "# obs_names = [\"peak infected\", \"time to peak\", \"total recovered\", \"duration\"]\n",
        "\n",
        "# ========== OPTION C: Your Simulator ==========\n",
        "# simulator = your_simulator\n",
        "# prior = utils.BoxUniform(\n",
        "#     low=torch.tensor([...]),   # Your parameter lower bounds\n",
        "#     high=torch.tensor([...])   # Your parameter upper bounds\n",
        "# )\n",
        "# param_names = [...]  # Your parameter names\n",
        "# obs_names = [...]    # Your observable names\n",
        "\n",
        "print(f\"Selected simulator: {simulator.__name__}\")\n",
        "print(f\"Parameters: {param_names}\")\n",
        "print(f\"Observables: {obs_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Generate \"Observed\" Data\n",
        "\n",
        "In a real application, this would be your experimental data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic observation (ground truth for testing)\n",
        "true_params = prior.sample()\n",
        "observed_data = simulator(true_params)\n",
        "\n",
        "print(\"\\n\ud83c\udfaf True parameters (hidden in real applications):\")\n",
        "for i, name in enumerate(param_names):\n",
        "    print(f\"  {name}: {true_params[i]:.3f}\")\n",
        "\n",
        "print(\"\\n\ud83d\udcca Observed data:\")\n",
        "for i, name in enumerate(obs_names):\n",
        "    print(f\"  {name}: {observed_data[i]:.3f}\")\n",
        "\n",
        "print(\"\\n\ud83c\udfb2 Challenge: Can we recover the true parameters from observations alone?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Run Neural Posterior Estimation \ud83d\ude80\n",
        "\n",
        "The same 4-step workflow from Exercise 1!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Create NPE object\n",
        "npe = inference.NPE(prior=prior)\n",
        "\n",
        "# Step 2: Train on simulations\n",
        "print(\"\ud83c\udfc3 Training neural network...\")\n",
        "print(\"This will take 20-40 seconds...\\n\")\n",
        "\n",
        "npe = npe.append_simulations(\n",
        "    simulator,\n",
        "    num_simulations=5000  # Use 10000+ for better results\n",
        ").train()\n",
        "\n",
        "# Step 3: Build posterior for our observation\n",
        "posterior = npe.build_posterior()\n",
        "\n",
        "# Step 4: Sample from posterior\n",
        "posterior_samples = posterior.sample(\n",
        "    (2000,),\n",
        "    x=observed_data,\n",
        "    show_progress_bars=True\n",
        ")\n",
        "\n",
        "print(\"\\n\u2705 Inference complete! Let's see what we learned...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Visualize Results \ud83d\udcca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare posterior to prior and truth\n",
        "fig, axes = plt.subplots(1, len(true_params), figsize=(4*len(true_params), 4))\n",
        "\n",
        "# Handle single parameter case\n",
        "if len(true_params) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    # Posterior\n",
        "    ax.hist(posterior_samples[:, i], bins=30, alpha=0.7, \n",
        "            density=True, label='Posterior', color='green', edgecolor='darkgreen')\n",
        "    \n",
        "    # Prior  \n",
        "    prior_samples = prior.sample((1000,))\n",
        "    ax.hist(prior_samples[:, i], bins=30, alpha=0.3,\n",
        "            density=True, label='Prior', color='gray', edgecolor='black')\n",
        "    \n",
        "    # Truth\n",
        "    ax.axvline(true_params[i], color='red', linewidth=2,\n",
        "              linestyle='--', label='True value')\n",
        "    \n",
        "    # Posterior mean\n",
        "    post_mean = posterior_samples[:, i].mean()\n",
        "    ax.axvline(post_mean, color='blue', linewidth=2,\n",
        "              linestyle='-', label='Post. mean')\n",
        "    \n",
        "    ax.set_xlabel(param_names[i], fontsize=12)\n",
        "    ax.set_ylabel('Density', fontsize=12)\n",
        "    ax.legend(fontsize=10, loc='upper right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "plt.suptitle('Posterior vs Prior: Learning from Data', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print quantitative summary\n",
        "print(\"\\n\ud83d\udcc8 Parameter Recovery Summary:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Parameter':<20} {'True':<10} {'Post. Mean \u00b1 Std':<20} {'Error':<10}\")\n",
        "print(\"-\"*60)\n",
        "for i, name in enumerate(param_names):\n",
        "    true_val = true_params[i].item()\n",
        "    post_mean = posterior_samples[:, i].mean().item()\n",
        "    post_std = posterior_samples[:, i].std().item()\n",
        "    error = abs(true_val - post_mean)\n",
        "    print(f\"{name:<20} {true_val:<10.3f} {post_mean:.3f} \u00b1 {post_std:.3f}  {error:<10.3f}\")\n",
        "\n",
        "# Calculate credible intervals\n",
        "print(\"\\n\ud83d\udcca 95% Credible Intervals:\")\n",
        "for i, name in enumerate(param_names):\n",
        "    q_low = torch.quantile(posterior_samples[:, i], 0.025).item()\n",
        "    q_high = torch.quantile(posterior_samples[:, i], 0.975).item()\n",
        "    true_val = true_params[i].item()\n",
        "    in_ci = \"\u2705\" if q_low <= true_val <= q_high else \"\u274c\"\n",
        "    print(f\"  {name}: [{q_low:.3f}, {q_high:.3f}] {in_ci}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Diagnostic - Posterior Predictive Check \ud83d\udd0d\n",
        "\n",
        "Can parameters from our posterior reproduce the observed data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate posterior predictive samples\n",
        "n_predictive = 200\n",
        "predictive_data = []\n",
        "\n",
        "print(\"Generating posterior predictive samples...\")\n",
        "for _ in range(n_predictive):\n",
        "    # Sample parameters from posterior\n",
        "    param_sample = posterior.sample((1,), x=observed_data)\n",
        "    # Simulate with those parameters\n",
        "    sim_data = simulator(param_sample[0])\n",
        "    predictive_data.append(sim_data)\n",
        "\n",
        "predictive_data = torch.stack(predictive_data)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, len(observed_data), figsize=(4*len(observed_data), 4))\n",
        "\n",
        "if len(observed_data) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    # Predictive distribution\n",
        "    ax.hist(predictive_data[:, i], bins=25, alpha=0.6, \n",
        "            label='Predictive', color='blue', density=True)\n",
        "    \n",
        "    # Observed value\n",
        "    ax.axvline(observed_data[i], color='red', linewidth=2,\n",
        "              linestyle='--', label='Observed')\n",
        "    \n",
        "    # Add percentiles\n",
        "    q5 = torch.quantile(predictive_data[:, i], 0.05)\n",
        "    q95 = torch.quantile(predictive_data[:, i], 0.95)\n",
        "    ax.axvspan(q5, q95, alpha=0.2, color='blue', label='90% CI')\n",
        "    \n",
        "    ax.set_xlabel(obs_names[i], fontsize=12)\n",
        "    ax.set_ylabel('Density', fontsize=12)\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(\"Posterior Predictive Check: Can We Reproduce the Data?\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check if observations fall within predictive distribution\n",
        "print(\"\\n\u2705 Diagnostic Results:\")\n",
        "for i, name in enumerate(obs_names):\n",
        "    percentile = (predictive_data[:, i] < observed_data[i]).float().mean() * 100\n",
        "    print(f\"  {name}: Observed value is at {percentile:.1f}th percentile\")\n",
        "    if 5 < percentile < 95:\n",
        "        print(f\"    \u2705 Well within predictive distribution\")\n",
        "    else:\n",
        "        print(f\"    \u26a0\ufe0f Near edge of predictive distribution\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 If observed data falls within the predictive distribution,\")\n",
        "print(\"   our posterior is consistent with the observations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Explore Parameter Correlations \ud83d\udd17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(param_names) > 1:\n",
        "    # Compute correlation matrix\n",
        "    correlation_matrix = torch.corrcoef(posterior_samples.T)\n",
        "    \n",
        "    # Visualize\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    im = plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
        "    plt.colorbar(im, label='Correlation')\n",
        "    \n",
        "    # Add labels\n",
        "    n_params = len(param_names)\n",
        "    plt.xticks(range(n_params), param_names, rotation=45, ha='right')\n",
        "    plt.yticks(range(n_params), param_names)\n",
        "    \n",
        "    # Add correlation values\n",
        "    for i in range(n_params):\n",
        "        for j in range(n_params):\n",
        "            text = plt.text(j, i, f'{correlation_matrix[i, j]:.2f}',\n",
        "                           ha=\"center\", va=\"center\", \n",
        "                           color=\"white\" if abs(correlation_matrix[i, j]) > 0.5 else \"black\",\n",
        "                           fontsize=12, fontweight='bold')\n",
        "    \n",
        "    plt.title('Parameter Correlations in Posterior', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Identify strong correlations\n",
        "    print(\"\\n\ud83d\udd17 Parameter Correlations:\")\n",
        "    for i in range(n_params):\n",
        "        for j in range(i+1, n_params):\n",
        "            corr = correlation_matrix[i, j].item()\n",
        "            if abs(corr) > 0.3:\n",
        "                strength = \"Strong\" if abs(corr) > 0.7 else \"Moderate\"\n",
        "                direction = \"positive\" if corr > 0 else \"negative\"\n",
        "                print(f\"  {param_names[i]} \u2194 {param_names[j]}: {strength} {direction} ({corr:.2f})\")\n",
        "    \n",
        "    print(\"\\n\ud83d\udca1 Correlations reveal parameter trade-offs and identifiability issues!\")\n",
        "else:\n",
        "    print(\"Single parameter - no correlations to show.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Experiments & What-If Analysis \ud83d\udd2c\n",
        "\n",
        "Let's explore how different choices affect our inference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment 1: What if we had noisier observations?\n",
        "print(\"\ud83d\udd2c Experiment 1: Effect of Observation Noise\\n\")\n",
        "\n",
        "# Add extra noise to observations\n",
        "noisy_obs = observed_data * (1 + torch.randn_like(observed_data) * 0.2)\n",
        "\n",
        "# Get posterior for noisy data\n",
        "noisy_posterior_samples = posterior.sample((500,), x=noisy_obs)\n",
        "\n",
        "print(f\"Original observations: {observed_data.numpy()}\")\n",
        "print(f\"Noisy observations:    {noisy_obs.numpy()}\")\n",
        "print(f\"\\nPosterior uncertainty (std):\")\n",
        "print(f\"  Original: {posterior_samples.std(dim=0).numpy()}\")\n",
        "print(f\"  Noisy:    {noisy_posterior_samples.std(dim=0).numpy()}\")\n",
        "print(\"\\n\ud83d\udca1 Noisier observations \u2192 higher posterior uncertainty!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment 2: How many simulations do we really need?\n",
        "print(\"\ud83d\udd2c Experiment 2: Effect of Training Data Size\\n\")\n",
        "\n",
        "# Train with fewer simulations\n",
        "small_npe = inference.NPE(prior=prior)\n",
        "small_npe = small_npe.append_simulations(\n",
        "    simulator,\n",
        "    num_simulations=500  # 10x fewer!\n",
        ").train(show_train_summary=False)\n",
        "\n",
        "small_posterior = small_npe.build_posterior()\n",
        "small_samples = small_posterior.sample((500,), x=observed_data)\n",
        "\n",
        "# Compare accuracy\n",
        "print(\"Parameter recovery (distance from truth):\")\n",
        "for i, name in enumerate(param_names):\n",
        "    error_5000 = abs(posterior_samples[:, i].mean() - true_params[i]).item()\n",
        "    error_500 = abs(small_samples[:, i].mean() - true_params[i]).item()\n",
        "    print(f\"  {name}:\")\n",
        "    print(f\"    5000 sims: error = {error_5000:.4f}\")\n",
        "    print(f\"    500 sims:  error = {error_500:.4f}\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 More simulations \u2192 better parameter recovery!\")\n",
        "print(\"   But diminishing returns after ~10,000 simulations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Challenge: Multiple Observations\n",
        "\n",
        "What if you had multiple independent observations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate multiple observations with the same true parameters\n",
        "n_observations = 3\n",
        "multi_obs = torch.stack([simulator(true_params) for _ in range(n_observations)])\n",
        "\n",
        "print(f\"\ud83d\udd04 Generated {n_observations} independent observations:\")\n",
        "for i, obs in enumerate(multi_obs):\n",
        "    print(f\"  Obs {i+1}: {obs.numpy()}\")\n",
        "\n",
        "# Strategy 1: Use the mean observation\n",
        "mean_obs = multi_obs.mean(dim=0)\n",
        "print(f\"\\n\ud83d\udcca Mean observation: {mean_obs.numpy()}\")\n",
        "\n",
        "# Get posterior for mean observation\n",
        "multi_posterior_samples = posterior.sample((1000,), x=mean_obs)\n",
        "\n",
        "# Compare uncertainties\n",
        "print(\"\\n\ud83d\udcc8 Posterior uncertainty (std):\")\n",
        "print(f\"  Single obs:   {posterior_samples.std(dim=0).numpy()}\")\n",
        "print(f\"  Mean of {n_observations} obs: {multi_posterior_samples.std(dim=0).numpy()}\")\n",
        "\n",
        "print(\"\\n\u2705 Multiple observations reduce uncertainty!\")\n",
        "print(\"\\n\ud83d\udca1 Advanced: For proper treatment of multiple observations,\")\n",
        "print(\"   retrain NPE with concatenated observations or use Sequential NPE.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf89 Congratulations!\n",
        "\n",
        "You've successfully:\n",
        "- \u2705 Applied SBI to different problems\n",
        "- \u2705 Learned the universal NPE workflow\n",
        "- \u2705 Performed diagnostic checks\n",
        "- \u2705 Explored how choices affect inference\n",
        "\n",
        "### \ud83d\udd11 Key Takeaways:\n",
        "\n",
        "1. **SBI is universal** - Same workflow for any simulator!\n",
        "2. **Prior choice matters** - Must cover true parameters\n",
        "3. **Diagnostics are essential** - Always check predictive distributions\n",
        "4. **More data = less uncertainty** - Both simulations and observations help\n",
        "5. **Parameters can be correlated** - Trade-offs and identifiability\n",
        "\n",
        "### \ud83d\ude80 Next Steps:\n",
        "\n",
        "For your research:\n",
        "1. **Start simple** - Test with synthetic data first\n",
        "2. **Scale up gradually** - Increase complexity step by step\n",
        "3. **Use Sequential NPE** - More efficient for expensive simulators\n",
        "4. **Try other methods** - NLE, NRE for different use cases\n",
        "\n",
        "### \ud83d\udcda Resources:\n",
        "\n",
        "- \ud83d\udcd6 [SBI Documentation](https://sbi-dev.github.io/sbi)\n",
        "- \ud83d\udcbb [GitHub Repository](https://github.com/sbi-dev/sbi)\n",
        "- \ud83d\udcf0 [JOSS Paper](https://joss.theoj.org/papers/10.21105/joss.02505)\n",
        "- \ud83d\udcac [Community Forum](https://github.com/sbi-dev/sbi/discussions)\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude4f Thank you for participating!\n",
        "\n",
        "**Now go forth and quantify uncertainty in your simulators!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
